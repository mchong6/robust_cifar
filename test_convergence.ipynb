{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from glob import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# from tensorboard import notebook\n",
    "from advertorch.attacks import LinfPGDAttack\n",
    "from advertorch.attacks import L2PGDAttack\n",
    "from advertorch.utils import NormalizeByChannelMeanStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "MEAN = torch.Tensor([0.4914, 0.4822, 0.4465])\n",
    "STD = torch.Tensor([0.2023, 0.1994, 0.2010])\n",
    "\n",
    "def BIM(image, classifier, target, eps, itr_eps=1 / 255, itr=10):\n",
    "    origin = image.clone()\n",
    "    for _ in range(itr):\n",
    "        image.requires_grad = True\n",
    "        out_image = image\n",
    "        with torch.enable_grad():\n",
    "            output = classifier(out_image)\n",
    "            loss = criterion(output, target)\n",
    "        grad = torch.autograd.grad(loss, [image])[0]\n",
    "        image = image.detach() + itr_eps * torch.sign(grad.detach())\n",
    "        image = torch.min(torch.max(image, origin - eps), origin + eps)\n",
    "        image = image.clamp(0, 1).detach()\n",
    "    return image.detach()\n",
    "\n",
    "def pgd_lbfgs(image, classifier, target, max_eps=8/255, itr_eps=1 / 255, itr=5, criterion=nn.CrossEntropyLoss()):\n",
    "    original = image.clone()\n",
    "    eps = torch.zeros_like(image)\n",
    "#     if np.random.randint(0, 1):\n",
    "#         eps.uniform_(-max_eps, max_eps).cuda()\n",
    "\n",
    "    for _ in range(itr):\n",
    "        lbfgs_optimizer = optim.LBFGS([eps.requires_grad_()], lr=1, max_iter=20, history_size=100)\n",
    "        def closure():\n",
    "            eps_ = F.tanh(eps) * max_eps\n",
    "            output = classifier(normalize((image+eps_).clamp(0,1)))\n",
    "            loss = -criterion(output, target)# + 1e1*F.mse_loss(eps, torch.zeros_like(eps))\n",
    "#             print(loss.mean(), loss.min(), loss.max())\n",
    "#             loss=loss.mean()\n",
    "            lbfgs_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        lbfgs_optimizer.step(closure)\n",
    "#         print(255*eps.max(), 255*eps.median(),255*eps.min())\n",
    "#         eps = eps.clamp(-max_eps, max_eps).detach()\n",
    "        eps = eps.detach()\n",
    "\n",
    "    return (image + F.tanh(eps)*max_eps).clamp(0,1)\n",
    "\n",
    "def robustify(im, classifier, target, iterations):\n",
    "    warm_iterations = iterations // 10\n",
    "    robust_eps = torch.zeros_like(im).cuda()\n",
    "    \n",
    "    adversary = L2PGDAttack(\n",
    "        classifier, eps=1., eps_iter=0.1, nb_iter=5,\n",
    "        rand_init=True, targeted=True)\n",
    "    \n",
    "#     optimizer = torch.optim.Adam([robust_eps.requires_grad_()], lr=1e-2)\n",
    "\n",
    "    for j in range(iterations):\n",
    "        robust_eps.requires_grad_()\n",
    "        robust_im = (im+robust_eps).clamp(0,1)\n",
    "        if j > warm_iterations:\n",
    "            eps = (adversary.perturb(robust_im, target) - robust_im).detach()\n",
    "        else:\n",
    "            eps = torch.zeros_like(im).cuda()\n",
    "        output = classifier((robust_im +eps).clamp(0, 1))\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        robust_eps = (robust_eps + 1/255*robust_eps.grad.data.sign()).clamp(-8/255,8/255).detach()\n",
    "        \n",
    "    out = (im+robust_eps).clamp(0,1)\n",
    "    return out\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "norm = NormalizeByChannelMeanStd(\n",
    "    mean=MEAN, std=STD).cuda()\n",
    "\n",
    "classifier = torch.nn.DataParallel(nn.Sequential(norm, ResNet18())).cuda().eval()\n",
    "# classifier = nn.DataParallel(ResNet18())\n",
    "# checkpoint = torch.load('./checkpoint/ckpt_grad_cw.t7')\n",
    "checkpoint = torch.load('./checkpoint/ckpt_madry+grad2.t7')\n",
    "# checkpoint = torch.load('./checkpoint/ckpt_accumulate_10_scale1_warm1.t7')\n",
    "classifier.load_state_dict(checkpoint['net'])\n",
    "# classifier = nn.Sequential(norm, classifier).cuda().eval()\n",
    "\n",
    "classifier_norm = nn.Sequential(norm, ResNet18()).cuda().eval()\n",
    "# checkpoint = torch.load('./checkpoint/ckpt_accumulate_10_scale1_warm1.t7')\n",
    "# checkpoint = torch.load('./checkpoint/ckpt_robust.t7')\n",
    "# checkpoint = torch.load('./checkpoint/ckpt_sub_accumulate_1_scale0_warm0.t7')\n",
    "# checkpoint = torch.load('./checkpoint/ckpt_madry.t7')\n",
    "# checkpoint2 = torch.load('./checkpoint/ckpt.t7')\n",
    "# classifier_norm.load_state_dict(checkpoint2['net'])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9d840c798c48aea0bf27b863292655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.437\n"
     ]
    }
   ],
   "source": [
    "from advertorch.attacks import L2PGDAttack\n",
    "\n",
    "max_eps = 0.25\n",
    "adversary = L2PGDAttack(\n",
    "    classifier, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"), eps=max_eps,\n",
    "    nb_iter=20, eps_iter=max_eps/5, rand_init=True, clip_min=0.0, clip_max=1.0,\n",
    "    targeted=False)\n",
    "\n",
    "# adv_untargeted = adversary.perturb(cln_data, true_label)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for itr, (real_im, target) in enumerate(tqdm_notebook(testloader)):\n",
    "    real_im, target = real_im.cuda(), target.cuda()\n",
    "    \n",
    "#     fake_im = robustify(real_im, adv_model, target, 50)\n",
    "#     fake_im = sparse_attack(real_im, target, adv_model, 8/255, 1/255, 200)\n",
    "    fake_im = BIM(real_im, classifier, target, 8/255, itr_eps=1/255, itr=20)\n",
    "#     fake_im = adversary.perturb(real_im, target)\n",
    "#     fake_im = pgd_lbfgs(real_im, classifier, target, max_eps=8/255, itr_eps=2 / 255, itr=5)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "#         outputs = classifier(real_im)\n",
    "        outputs = classifier(fake_im)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "#         print(correct/total)\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_class = classifier(normalize(out)).argmax(1)\n",
    "# print((out_class==target).sum()/out_class.size(0))\n",
    "\n",
    "out_class = classifier(real_im).argmax(1)\n",
    "adv = BIM(real_im, classifier, out_class, 50 / 255, itr=100).detach()\n",
    "adv_class = classifier(adv).argmax(1)\n",
    "# print((adv_class==target).sum().float()/adv_class.size(0))\n",
    "# adv_ = util.attack(adv, classifier, adv_class, 50 / 255, 200, attack_method=\"BIM\").detach()\n",
    "# adv2_class = classifier(normalize(adv_)).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "car\n",
      "horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 7\n",
    "util.display_image(real_im[idx])\n",
    "util.display_image(adv[idx])\n",
    "print(classes[target[idx]])\n",
    "print(classes[out_class[idx]])\n",
    "print(classes[adv_class[idx]])\n",
    "# print(classes[adv2_class[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        self.embed = nn.Embedding(num_classes, num_features * 2)\n",
    "        self.embed.weight.data[:, :num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
    "        self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.bn(x)\n",
    "        gamma, beta = self.embed(y).chunk(2, 1)\n",
    "        out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
    "        return out\n",
    "\n",
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        num_filters = 128\n",
    "        kernel_size = 3\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        \n",
    "        self.conv = nn.utils.spectral_norm(nn.Conv2d(num_features, num_filters, kernel_size=(kernel_size, kernel_size), padding=1))\n",
    "        self.conv_gamma = nn.utils.spectral_norm(nn.Conv2d(num_filters, num_features, kernel_size=(kernel_size, kernel_size), padding=1))\n",
    "        self.conv_beta = nn.utils.spectral_norm(nn.Conv2d(num_filters, num_features, kernel_size=(kernel_size, kernel_size), padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn(x)\n",
    "        \n",
    "        seg = F.relu(self.conv(x))\n",
    "        seg_gamma = self.conv_gamma(seg)\n",
    "        seg_beta = self.conv_beta(seg)\n",
    "        \n",
    "        print(seg_gamma.shape, seg_beta.shape)\n",
    "        out = torch.matmul(seg_gamma, x) + seg_beta\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "bn = ConditionalBatchNorm2d(3)\n",
    "z = torch.randn([1,3,224,224])\n",
    "bn(z).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
